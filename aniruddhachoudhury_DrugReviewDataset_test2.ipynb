{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "aniruddhachoudhury/DrugReviewDataset/test2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN+AKSyiiByEtA1hlklR6t3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "370af44a9fa445f8a1af603e4dd59668": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f13ab72d101b4cce9f12d6b338f2f072",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_7e8c1d245d2c4634ab9d59515795d983",
              "IPY_MODEL_9ccb43dbfd2d415d87140721318c9f9a"
            ]
          }
        },
        "f13ab72d101b4cce9f12d6b338f2f072": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7e8c1d245d2c4634ab9d59515795d983": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c8e86f87a48345e48aad8c8f6a45ab75",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_52c5b12029d84f5196a4e9f2d1b116ab"
          }
        },
        "9ccb43dbfd2d415d87140721318c9f9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_73486b5665b34dfc92b8702280548e54",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 822kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2874ae5c857e40a7a4ab016af0107ce0"
          }
        },
        "c8e86f87a48345e48aad8c8f6a45ab75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "52c5b12029d84f5196a4e9f2d1b116ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "73486b5665b34dfc92b8702280548e54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2874ae5c857e40a7a4ab016af0107ce0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0c112e49ae384537987f3b6baaf7d415": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c09066242ad448f6b620feb6b176cd9c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ad87400818704da5996dbc095ed0438f",
              "IPY_MODEL_ece125c9c2ef4240b2e37553328da8a6"
            ]
          }
        },
        "c09066242ad448f6b620feb6b176cd9c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ad87400818704da5996dbc095ed0438f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_5c187dc4ca964bcc920a77fa9646cefd",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7a3ba0b1bb854079944e693dc9b10df2"
          }
        },
        "ece125c9c2ef4240b2e37553328da8a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c3ee231fb22b4920ada1070f14ac9f18",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:08&lt;00:00, 49.4B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e82a187b8a904ab4915c4ba546d899c9"
          }
        },
        "5c187dc4ca964bcc920a77fa9646cefd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7a3ba0b1bb854079944e693dc9b10df2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c3ee231fb22b4920ada1070f14ac9f18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e82a187b8a904ab4915c4ba546d899c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4134637bae8c467a9e334ea932540b9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b758a322965c462aad047f06d5fe9091",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4c492fe8f7c04f0eb8acf9cff91ad792",
              "IPY_MODEL_2d4149ff39ea4342aac2c64f4f219f0b"
            ]
          }
        },
        "b758a322965c462aad047f06d5fe9091": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4c492fe8f7c04f0eb8acf9cff91ad792": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b3ad238eeb83441f8a7dc0f4f594f41a",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a9d52f3139e44b438be7587a092feebc"
          }
        },
        "2d4149ff39ea4342aac2c64f4f219f0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ec9f0fa541704d7f8dcc35faf18d5679",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [00:05&lt;00:00, 74.7MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_67e369fb0d9c421c9794364627ddb64a"
          }
        },
        "b3ad238eeb83441f8a7dc0f4f594f41a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a9d52f3139e44b438be7587a092feebc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ec9f0fa541704d7f8dcc35faf18d5679": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "67e369fb0d9c421c9794364627ddb64a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rykah14/DrugReviewDataset/blob/main/aniruddhachoudhury_DrugReviewDataset_test2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLJShceY_jYM"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZPjC5oBSmko1",
        "outputId": "c831df28-e4d8-47d3-921a-1584de8981ed"
      },
      "source": [
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wmFO1My4mv9Q",
        "outputId": "b2ca5703-0e6d-4d5b-f0d2-9a24bbf1fc1b"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/50/0c/7d5950fcd80b029be0a8891727ba21e0cd27692c407c51261c3c921f6da3/transformers-4.1.1-py3-none-any.whl (1.5MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5MB 8.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.8)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Collecting tokenizers==0.9.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/1c/e789a8b12e28be5bc1ce2156cf87cb522b379be9cadc7ad8091a4cc107c4/tokenizers-0.9.4-cp36-cp36m-manylinux2010_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 29.0MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 51.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.19.4)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.0.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=e263c34dca603c117899775355928fe60da972570e4bd2478e1fe750311986bc\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.43 tokenizers-0.9.4 transformers-4.1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LlsBB2C9mzjC",
        "outputId": "1de87132-d355-41c1-a6d4-75b30e444469"
      },
      "source": [
        "!pip install wget"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wget\n",
            "  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-cp36-none-any.whl size=9682 sha256=7479f8786490cc78f2f7b77520f590c902179eaf83e07bd13fa2dc2254c6ea77\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mTOO2_xlm-f6",
        "outputId": "28d2ae31-41b5-4357-9dd2-ff5948ef7b03"
      },
      "source": [
        "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/00462/drugsCom_raw.zip"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-01-07 09:59:29--  https://archive.ics.uci.edu/ml/machine-learning-databases/00462/drugsCom_raw.zip\n",
            "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
            "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 42989872 (41M) [application/x-httpd-php]\n",
            "Saving to: ‘drugsCom_raw.zip’\n",
            "\n",
            "drugsCom_raw.zip    100%[===================>]  41.00M  65.1MB/s    in 0.6s    \n",
            "\n",
            "2021-01-07 09:59:30 (65.1 MB/s) - ‘drugsCom_raw.zip’ saved [42989872/42989872]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kBWUKrVNnAP5",
        "outputId": "247ca0f4-f2d8-4969-f9e2-dcca0f5f68c1"
      },
      "source": [
        "!unzip drugsCom_raw.zip"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  drugsCom_raw.zip\n",
            "  inflating: drugsComTest_raw.tsv    \n",
            "  inflating: drugsComTrain_raw.tsv   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 580
        },
        "id": "HmriIuytnCpS",
        "outputId": "dd7aedb1-b694-4a86-f6fd-ab05d8080fae"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset into a pandas dataframe.\n",
        "df = pd.read_table(\"drugsComTest_raw.tsv\", delimiter='\\t', header=None, names=['drugName','condition','review',\t'rating'\t,'date','usefulCount'])\n",
        "\n",
        "# Report the number of sentences.\n",
        "print('Number of training sentences: {:,}\\n'.format(df.shape[0]))\n",
        "\n",
        "# Display 10 random rows from the data.\n",
        "df.sample(10)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training sentences: 53,767\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>drugName</th>\n",
              "      <th>condition</th>\n",
              "      <th>review</th>\n",
              "      <th>rating</th>\n",
              "      <th>date</th>\n",
              "      <th>usefulCount</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>155067.0</th>\n",
              "      <td>Metronidazole</td>\n",
              "      <td>Bacterial Infection</td>\n",
              "      <td>\"I had Mirena for 2 years and suffered from\\r\\...</td>\n",
              "      <td>8.0</td>\n",
              "      <td>July 12, 2016</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73010.0</th>\n",
              "      <td>Ethinyl estradiol / norethindrone</td>\n",
              "      <td>Birth Control</td>\n",
              "      <td>\"By far the best birth control pill I&amp;#039;ve ...</td>\n",
              "      <td>10.0</td>\n",
              "      <td>March 11, 2015</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>224665.0</th>\n",
              "      <td>Bupropion</td>\n",
              "      <td>Smoking Cessation</td>\n",
              "      <td>\"Okay, so I started taking this to assist me i...</td>\n",
              "      <td>9.0</td>\n",
              "      <td>June 30, 2017</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99949.0</th>\n",
              "      <td>Magnesium sulfate / potassium sulfate / sodium...</td>\n",
              "      <td>Bowel Preparation</td>\n",
              "      <td>\"It tastes SO BAD. I don&amp;#039;t know how the g...</td>\n",
              "      <td>10.0</td>\n",
              "      <td>December 29, 2015</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>115495.0</th>\n",
              "      <td>Propofol</td>\n",
              "      <td>Anesthesia</td>\n",
              "      <td>\"I went in today for an Upper GI endoscopy and...</td>\n",
              "      <td>9.0</td>\n",
              "      <td>January 14, 2014</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>89050.0</th>\n",
              "      <td>Singulair</td>\n",
              "      <td>Allergic Rhinitis</td>\n",
              "      <td>\"I never had allergies until I was an adult. M...</td>\n",
              "      <td>7.0</td>\n",
              "      <td>October 26, 2015</td>\n",
              "      <td>34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82542.0</th>\n",
              "      <td>Liraglutide</td>\n",
              "      <td>NaN</td>\n",
              "      <td>\"I&amp;#039;ve been really pleased with the low bl...</td>\n",
              "      <td>8.0</td>\n",
              "      <td>July 9, 2010</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146791.0</th>\n",
              "      <td>Alprazolam</td>\n",
              "      <td>Anxiety</td>\n",
              "      <td>\"Helps wth anxiety but makes me very sleepy, r...</td>\n",
              "      <td>7.0</td>\n",
              "      <td>May 10, 2017</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>219238.0</th>\n",
              "      <td>Ortho Cyclen</td>\n",
              "      <td>Birth Control</td>\n",
              "      <td>\"I have been on this pill for almost two years...</td>\n",
              "      <td>6.0</td>\n",
              "      <td>October 17, 2013</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7889.0</th>\n",
              "      <td>Xanax</td>\n",
              "      <td>Anxiety</td>\n",
              "      <td>\"Just great. I do not use the prescribed amoun...</td>\n",
              "      <td>10.0</td>\n",
              "      <td>February 19, 2012</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   drugName  ... usefulCount\n",
              "155067.0                                      Metronidazole  ...           4\n",
              "73010.0                   Ethinyl estradiol / norethindrone  ...           0\n",
              "224665.0                                          Bupropion  ...          13\n",
              "99949.0   Magnesium sulfate / potassium sulfate / sodium...  ...           4\n",
              "115495.0                                           Propofol  ...          22\n",
              "89050.0                                           Singulair  ...          34\n",
              "82542.0                                         Liraglutide  ...           8\n",
              "146791.0                                         Alprazolam  ...          18\n",
              "219238.0                                       Ortho Cyclen  ...           4\n",
              "7889.0                                                Xanax  ...          14\n",
              "\n",
              "[10 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zd-x2wkBrtJM"
      },
      "source": [
        "!sed -e 's/\"/'\\''/g' ./drugsComTest_raw.tsv > ./drugsComTest_raw_re.tsv"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BeYz7zs4mB5I",
        "outputId": "91a720ba-00e1-4d3a-ce43-57b225437948"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# データの読込\n",
        "df = pd.read_table('./drugsComTest_raw_re.tsv', header=None, sep='\\t', names=['drugName','condition','review',\t'rating'\t,'date','usefulCount'])\n",
        "\n",
        "# データの抽出\n",
        "df = df.loc[df['condition'].isin(['Depression','Pain']), ['condition', 'review']]\n",
        "#ADHDは削除して2値分類\n",
        "df=df.replace('Depression', 0)\n",
        "df=df.replace('Pain', 1)\n",
        "#のちのことを考慮してint型の数値にreplace\n",
        "#df=df.replace('ADHD', '2')\n",
        "print(df)\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "        condition                                             review\n",
            "163740          0  '''I&#039;ve tried a few antidepressants over ...\n",
            "178004          1  '''Been on 30mg Cymbalta for 2 weeks. Started ...\n",
            "141462          0  '''I am a 22 year old female college student. ...\n",
            "201582          0  '''Zoloft did not help me at all.  I was on it...\n",
            "131683          0  '''Sadly only lasted 5 days on Effexor XR. The...\n",
            "...           ...                                                ...\n",
            "164760          1  '''No side effects and back to work in a coupl...\n",
            "27561           0  '''I have been taking maprotiline for over 35 ...\n",
            "28754           0  '''I&#039;m a 19 year old girl and I&#039;ve b...\n",
            "23352           1  '''Have been taking it for 6 years (120 millig...\n",
            "47656           1  '''I was prescribed Nucynta for severe neck/sh...\n",
            "\n",
            "[5195 rows x 2 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "hqjLnuCQnbfL",
        "outputId": "c453aca2-d3a2-46e7-ae78-cb49692e4336"
      },
      "source": [
        "df.loc[df.condition == 0].sample(5)[['condition','review']]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>condition</th>\n",
              "      <th>review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>171591</th>\n",
              "      <td>0</td>\n",
              "      <td>'''I&amp;#039;ve been taking Wellbutrin for two ye...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>183091</th>\n",
              "      <td>0</td>\n",
              "      <td>'''I took this for depression and chronic back...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>168981</th>\n",
              "      <td>0</td>\n",
              "      <td>'''I developed Serotonin Syndrome.  Diarrhea (...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93179</th>\n",
              "      <td>0</td>\n",
              "      <td>'''Started of the 5mg Brintellix,  I usually h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>92851</th>\n",
              "      <td>0</td>\n",
              "      <td>'''I am currently in rehab I was addicted to b...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        condition                                             review\n",
              "171591          0  '''I&#039;ve been taking Wellbutrin for two ye...\n",
              "183091          0  '''I took this for depression and chronic back...\n",
              "168981          0  '''I developed Serotonin Syndrome.  Diarrhea (...\n",
              "93179           0  '''Started of the 5mg Brintellix,  I usually h...\n",
              "92851           0  '''I am currently in rehab I was addicted to b..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R4PBek_tnvi8"
      },
      "source": [
        "# Get the lists of sentences and their labels.\n",
        "conditions = df.condition.values\n",
        "reviews = df.review.values"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FeM-JgfvrcU6",
        "outputId": "72ebc77c-15da-401d-abc7-77d77d7332fc"
      },
      "source": [
        "print(reviews[1:10])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[\"'''Been on 30mg Cymbalta for 2 weeks. Started getting relief by the 2nd day. Am 58 year old male with spinal stenosis, degenerative disc disease, and spondy. Plan was to go to 60mg but I am getting enough relief at 30mg. I believe I will try to stay on that dose to minimize side effects. Some constipation, difficult reaching orgasm, some night sweats and minor headaches. Oh, insomnia if I took it at night.  I had samples of this medicine for 6 months but delayed starting it because of horror stories on the internet. Pain was ruining my life so this medicine seems to be the best option.'''\"\n",
            " \"'''I am a 22 year old female college student. I wanted to write this because when I was at my lowest of low when I felt absolutely hopeless... these positive reviews are what got me through the day. I experienced a lot of change.  I was also in a relationship that made me unhappy. I stopped doing the things I liked to do such as run, party, work, hang out with friends etc. In result, I never had energy. I constantly felt guilty. I cried everyday, sometimes multiple times of day. I went to group therapy. I dropped 10lbs in two weeks. I eventually got on this medicine &amp; the first 4 days felt crazy &amp; tired! TAKE AT NIGHT. Give this medicine time! Now 3 weeks in I am back to myself and am truly happy! Keep your head up.'''\"\n",
            " \"'''Zoloft did not help me at all.  I was on it for about 3 months, worked up to 100mg.  I was tired and hungry all the time.  I gained 20 lbs and slept all day. I was a complete zombie.  Definitely made my depression worse.'''\"\n",
            " \"'''Sadly only lasted 5 days on Effexor XR. The side effects from the 75mg dose was unlike anything I have experienced before. Within 10 hours of the first dose I had severe anxiety - something I had never experienced before. Within hours of second dose the extreme nausea came on. By day 3 I was pratically bed-ridden in cold sweats and feeling completely &quot;out of it&quot; . I persevered hoping the effects would begin to subside but by the 5th day I had severe nausea, couldn&#039;t get out of bed from feeling so sick, horrible tinnitus (ringing in the ears) and felt spaced out to the point that I began to wonder if I would ever feel &quot;normal&quot; again. Advised by GP to cease immediately on hearing my side effects.'''\"\n",
            " \"'''I have severe scar tissue and adhesions from mutiple surgeries and the pain was intense it is in my pelvic area. I fill like I&#039;m having a bad cycle every day and walking intensifies the pain this is a every day feeling. My doctor tried me on Ultram and it has been a God send. I take it three times a day. Without it it would be hard to walk so I give it a 10 thank you.'''\"\n",
            " \"'''I was first prescribed Effexor 13 years ago and was taking 225 mg. I was on it for a few years and stopped taking when I was pregnant with my first child. I was put on Paxil (gained so much weight) and then Zoloft. I took the Zoloft off and on for years until it just wasn&#039;t working for me anymore. I was then put on Welbutrin while still taking 25mg of Zoloft. I quit smoking (had no desire to smoke) but then became suicidal. My doctor then put me back on Effexor and I currently only take 75 mg. I feel amazing. Yeah the side effects are bad, I&#039;ve gained weight (lost weight the first time I was on it), have sexual side effects, and get quite shaky/jittery if I&#039;m late on a dose. But I&#039;m finally the mom I&#039;ve always wanted to be.'''\"\n",
            " \"'''I took Effexor for the first and last time yesterday around 7:41 am . At first I couldn&#039;t feel my arms or face and then it felt like fire works were going off in my head . I yawned all day long and each time I did I felt like my own tongue was gagging me . The worst of it was around 3:45 am I woke up shaking uncontrollably falling over couldn&#039;t see straight it felt like I was being electrocuted it was to the point I either wanted to be knocked out or die . My husband found me shaking and rocking back and forth in our living room floor . This drug for me personally was horrific .'''\"\n",
            " \"'''Was very beneficial when taken with a muscle relaxer for extreme pain in neck and arm. I was also taking Naproxen.'''\"\n",
            " \"'''I have been prescribed Vicodin 5/500s for over a year due to chronic headaches from a severe sinus problem.  \"]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83,
          "referenced_widgets": [
            "370af44a9fa445f8a1af603e4dd59668",
            "f13ab72d101b4cce9f12d6b338f2f072",
            "7e8c1d245d2c4634ab9d59515795d983",
            "9ccb43dbfd2d415d87140721318c9f9a",
            "c8e86f87a48345e48aad8c8f6a45ab75",
            "52c5b12029d84f5196a4e9f2d1b116ab",
            "73486b5665b34dfc92b8702280548e54",
            "2874ae5c857e40a7a4ab016af0107ce0"
          ]
        },
        "id": "6Ynw9e--oOAk",
        "outputId": "77c334f4-a7b2-45f8-cbed-76cba7ed5867"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading BERT tokenizer...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "370af44a9fa445f8a1af603e4dd59668",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mVWEoGPfoPpF",
        "outputId": "21ee66ae-bf90-4da6-c8cb-b4aa87be8474"
      },
      "source": [
        "tokenizer"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PreTrainedTokenizer(name_or_path='bert-base-uncased', vocab_size=30522, model_max_len=512, is_fast=False, padding_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BfKYmw-zoUK6",
        "outputId": "ba07d814-3384-4a71-bfe5-f03d9e298d56"
      },
      "source": [
        "# Print the original sentence.\n",
        "print(' Original: ', reviews[10])\n",
        "\n",
        "# Print the sentence split into tokens.\n",
        "print('Tokenized: ', tokenizer.tokenize(reviews[10]))\n",
        "\n",
        "# Print the sentence mapped to token ids.\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(reviews[10])))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Original:  '''Started taking it and I slept well at night and awoke early around 5 to start my day happily. But come 8 am and I am drowsy and needed to take already two hrs nap. Awake and resume\n",
            "Tokenized:  [\"'\", \"'\", \"'\", 'started', 'taking', 'it', 'and', 'i', 'slept', 'well', 'at', 'night', 'and', 'awoke', 'early', 'around', '5', 'to', 'start', 'my', 'day', 'happily', '.', 'but', 'come', '8', 'am', 'and', 'i', 'am', 'dr', '##ows', '##y', 'and', 'needed', 'to', 'take', 'already', 'two', 'hr', '##s', 'nap', '.', 'awake', 'and', 'resume']\n",
            "Token IDs:  [1005, 1005, 1005, 2318, 2635, 2009, 1998, 1045, 7771, 2092, 2012, 2305, 1998, 19179, 2220, 2105, 1019, 2000, 2707, 2026, 2154, 11361, 1012, 2021, 2272, 1022, 2572, 1998, 1045, 2572, 2852, 15568, 2100, 1998, 2734, 2000, 2202, 2525, 2048, 17850, 2015, 18996, 1012, 8300, 1998, 13746]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CvTb4M62pFr_",
        "outputId": "02d9275e-08e4-40e0-d3eb-b14530ddc104"
      },
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in reviews:\n",
        "    # `encode` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    encoded_sent = tokenizer.encode(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "\n",
        "                        # This function also supports truncation and conversion\n",
        "                        # to pytorch tensors, but we need to do padding, so we\n",
        "                        # can't use these features :( .\n",
        "                        #max_length = 128,          # Truncate all sentences.\n",
        "                        #return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.\n",
        "    input_ids.append(encoded_sent)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', reviews[10])\n",
        "print('Token IDs:', input_ids[10])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (609 > 512). Running this sequence through the model will result in indexing errors\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Original:  '''Started taking it and I slept well at night and awoke early around 5 to start my day happily. But come 8 am and I am drowsy and needed to take already two hrs nap. Awake and resume\n",
            "Token IDs: [101, 1005, 1005, 1005, 2318, 2635, 2009, 1998, 1045, 7771, 2092, 2012, 2305, 1998, 19179, 2220, 2105, 1019, 2000, 2707, 2026, 2154, 11361, 1012, 2021, 2272, 1022, 2572, 1998, 1045, 2572, 2852, 15568, 2100, 1998, 2734, 2000, 2202, 2525, 2048, 17850, 2015, 18996, 1012, 8300, 1998, 13746, 102]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iQ95z3iJodpM",
        "outputId": "a6e5a3cd-6303-400c-b6f6-a6eab1211bcd"
      },
      "source": [
        "print('Max sentence length: ', max([len(sen) for sen in input_ids]))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max sentence length:  609\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cdsuPu0-vvfk",
        "outputId": "08bcc467-ca92-4ded-c4df-e7647d3daf0f"
      },
      "source": [
        "# We'll borrow the `pad_sequences` utility function to do this.\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Set the maximum sequence length.\n",
        "# I've chosen 64 somewhat arbitrarily. It's slightly larger than the\n",
        "# maximum training sentence length of 47...\n",
        "MAX_LEN = 64\n",
        "\n",
        "print('\\nPadding/truncating all sentences to %d values...' % MAX_LEN)\n",
        "\n",
        "print('\\nPadding token: \"{:}\", ID: {:}'.format(tokenizer.pad_token, tokenizer.pad_token_id))\n",
        "\n",
        "# Pad our input tokens with value 0.\n",
        "# \"post\" indicates that we want to pad and truncate at the end of the sequence,\n",
        "# as opposed to the beginning.\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", \n",
        "                          value=0, truncating=\"post\", padding=\"post\")\n",
        "\n",
        "print('\\nDone.')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Padding/truncating all sentences to 64 values...\n",
            "\n",
            "Padding token: \"[PAD]\", ID: 0\n",
            "\n",
            "Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzpunIbLv01M"
      },
      "source": [
        "# Create attention masks\n",
        "attention_masks = []\n",
        "\n",
        "# For each sentence...\n",
        "for sent in input_ids:\n",
        "    \n",
        "    # Create the attention mask.\n",
        "    #   - If a token ID is 0, then it's padding, set the mask to 0.\n",
        "    #   - If a token ID is > 0, then it's a real token, set the mask to 1.\n",
        "    att_mask = [int(token_id > 0) for token_id in sent]\n",
        "    \n",
        "    # Store the attention mask for this sentence.\n",
        "    attention_masks.append(att_mask)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38A6GW3kv5cf"
      },
      "source": [
        "# Use train_test_split to split our data into train and validation sets for\n",
        "# training\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Use 90% for training and 10% for validation.\n",
        "train_inputs, validation_inputs, train_conditions, validation_conditions = train_test_split(input_ids, conditions, \n",
        "                                                            random_state=2018, test_size=0.1)\n",
        "# Do the same for the masks.\n",
        "train_masks, validation_masks, _, _ = train_test_split(attention_masks, conditions,\n",
        "                                             random_state=2018, test_size=0.1)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLdBvHg8wJQn"
      },
      "source": [
        "# Convert all inputs and labels into torch tensors, the required datatype \n",
        "# for our model.\n",
        "train_inputs = torch.tensor(train_inputs)\n",
        "validation_inputs = torch.tensor(validation_inputs)\n",
        "\n",
        "train_conditions = torch.tensor(train_conditions)\n",
        "validation_conditions = torch.tensor(validation_conditions)\n",
        "\n",
        "train_masks = torch.tensor(train_masks)\n",
        "validation_masks = torch.tensor(validation_masks)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ag0pjb1C4J-f"
      },
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# The DataLoader needs to know our batch size for training, so we specify it \n",
        "# here.\n",
        "# For fine-tuning BERT on a specific task, the authors recommend a batch size of\n",
        "# 16 or 32.\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "# Create the DataLoader for our training set.\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_conditions)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "# Create the DataLoader for our validation set.\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_conditions)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "0c112e49ae384537987f3b6baaf7d415",
            "c09066242ad448f6b620feb6b176cd9c",
            "ad87400818704da5996dbc095ed0438f",
            "ece125c9c2ef4240b2e37553328da8a6",
            "5c187dc4ca964bcc920a77fa9646cefd",
            "7a3ba0b1bb854079944e693dc9b10df2",
            "c3ee231fb22b4920ada1070f14ac9f18",
            "e82a187b8a904ab4915c4ba546d899c9",
            "4134637bae8c467a9e334ea932540b9f",
            "b758a322965c462aad047f06d5fe9091",
            "4c492fe8f7c04f0eb8acf9cff91ad792",
            "2d4149ff39ea4342aac2c64f4f219f0b",
            "b3ad238eeb83441f8a7dc0f4f594f41a",
            "a9d52f3139e44b438be7587a092feebc",
            "ec9f0fa541704d7f8dcc35faf18d5679",
            "67e369fb0d9c421c9794364627ddb64a"
          ]
        },
        "id": "7GVNU1HErqst",
        "outputId": "f8fbb826-69ab-4ae3-9dee-7178233452ce"
      },
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
        "# linear classification layer on top. \n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
        "    num_labels = 2, # The number of output labels--2 for binary classification.\n",
        "                    # You can increase this for multi-class tasks.   \n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        ")\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model.cuda()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0c112e49ae384537987f3b6baaf7d415",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4134637bae8c467a9e334ea932540b9f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GXobR03zsHyh",
        "outputId": "d1773354-11df-49de-d3b5-83c2381f4b76"
      },
      "source": [
        "# Get all of the model's parameters as a list of tuples.\n",
        "params = list(model.named_parameters())\n",
        "\n",
        "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
        "\n",
        "print('==== Embedding Layer ====\\n')\n",
        "\n",
        "for p in params[0:5]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== First Transformer ====\\n')\n",
        "\n",
        "for p in params[5:21]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== Output Layer ====\\n')\n",
        "\n",
        "for p in params[-4:]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The BERT model has 201 different named parameters.\n",
            "\n",
            "==== Embedding Layer ====\n",
            "\n",
            "bert.embeddings.word_embeddings.weight                  (30522, 768)\n",
            "bert.embeddings.position_embeddings.weight                (512, 768)\n",
            "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
            "bert.embeddings.LayerNorm.weight                              (768,)\n",
            "bert.embeddings.LayerNorm.bias                                (768,)\n",
            "\n",
            "==== First Transformer ====\n",
            "\n",
            "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
            "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
            "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
            "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
            "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
            "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
            "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
            "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
            "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
            "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
            "\n",
            "==== Output Layer ====\n",
            "\n",
            "bert.pooler.dense.weight                                  (768, 768)\n",
            "bert.pooler.dense.bias                                        (768,)\n",
            "classifier.weight                                           (2, 768)\n",
            "classifier.bias                                                 (2,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQmmZgnesJb0"
      },
      "source": [
        "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
        "# I believe the 'W' stands for 'Weight Decay fix\"\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 5e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  #5e-5でやる\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJLAsdgZsL_Y",
        "outputId": "0254111c-7f15-46b1-e8a9-fb7b44163e53"
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs (authors recommend between 2 and 4)\n",
        "epochs = 4\n",
        "\n",
        "# Total number of training steps is number of batches * number of epochs.\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)\n",
        "scheduler"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.optim.lr_scheduler.LambdaLR at 0x7f76d12cba20>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AMgLdT0LsO8t"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3FJbbti9sSNW"
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79Z5pm6NsUed",
        "outputId": "46a03eae-1002-4278-be67-4dc37cef30c1"
      },
      "source": [
        "import random\n",
        "\n",
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# Store the average loss after each epoch so we can plot them.\n",
        "loss_values = []\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_loss = 0\n",
        "\n",
        "    # Put the model into training mode. Don't be mislead--the call to \n",
        "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "    # `dropout` and `batchnorm` layers behave differently during training\n",
        "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "        # `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a\n",
        "        # backward pass. PyTorch doesn't do this automatically because \n",
        "        # accumulating the gradients is \"convenient while training RNNs\". \n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "        model.zero_grad()        \n",
        "\n",
        "        # Perform a forward pass (evaluate the model on this training batch).\n",
        "        # This will return the loss (rather than the model output) because we\n",
        "        # have provided the `labels`.\n",
        "        # The documentation for this `model` function is here: \n",
        "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "        outputs = model(b_input_ids, \n",
        "                    token_type_ids=None, \n",
        "                    attention_mask=b_input_mask, \n",
        "                    labels=b_labels)\n",
        "        \n",
        "        # The call to `model` always returns a tuple, so we need to pull the \n",
        "        # loss value out of the tuple.\n",
        "        loss = outputs[0]\n",
        "\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value \n",
        "        # from the tensor.\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over the training data.\n",
        "    avg_train_loss = total_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Store the loss value for plotting the learning curve.\n",
        "    loss_values.append(avg_train_loss)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        # Add batch to GPU\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        \n",
        "        # Unpack the inputs from our dataloader\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        \n",
        "        # Telling the model not to compute or store gradients, saving memory and\n",
        "        # speeding up validation\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # This will return the logits rather than the loss because we have\n",
        "            # not provided labels.\n",
        "            # token_type_ids is the same as the \"segment ids\", which \n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "            # The documentation for this `model` function is here: \n",
        "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "            outputs = model(b_input_ids, \n",
        "                            token_type_ids=None, \n",
        "                            attention_mask=b_input_mask)\n",
        "        \n",
        "        # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "        # values prior to applying an activation function like the softmax.\n",
        "        logits = outputs[0]\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "        \n",
        "        # Calculate the accuracy for this batch of test sentences.\n",
        "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "        \n",
        "        # Accumulate the total accuracy.\n",
        "        eval_accuracy += tmp_eval_accuracy\n",
        "\n",
        "        # Track the number of batches\n",
        "        nb_eval_steps += 1\n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
        "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    147.    Elapsed: 0:00:15.\n",
            "  Batch    80  of    147.    Elapsed: 0:00:30.\n",
            "  Batch   120  of    147.    Elapsed: 0:00:46.\n",
            "\n",
            "  Average training loss: 0.24\n",
            "  Training epcoh took: 0:00:56\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.96\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    147.    Elapsed: 0:00:17.\n",
            "  Batch    80  of    147.    Elapsed: 0:00:33.\n",
            "  Batch   120  of    147.    Elapsed: 0:00:49.\n",
            "\n",
            "  Average training loss: 0.09\n",
            "  Training epcoh took: 0:00:59\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.94\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    147.    Elapsed: 0:00:16.\n",
            "  Batch    80  of    147.    Elapsed: 0:00:32.\n",
            "  Batch   120  of    147.    Elapsed: 0:00:48.\n",
            "\n",
            "  Average training loss: 0.04\n",
            "  Training epcoh took: 0:00:59\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.95\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    147.    Elapsed: 0:00:16.\n",
            "  Batch    80  of    147.    Elapsed: 0:00:32.\n",
            "  Batch   120  of    147.    Elapsed: 0:00:48.\n",
            "\n",
            "  Average training loss: 0.02\n",
            "  Training epcoh took: 0:00:58\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.96\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "Training complete!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "id": "DFK47fx6tjxm",
        "outputId": "c3c4f1a9-9c0f-42c1-ca50-fa6c7f4edaa3"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(loss_values, 'b-o')\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.show()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}