{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "/DrugReviewDataset/multiclass_1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPsydjRs07YexPXlJBaoO0q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f08fdc05320542b8864507310afa073f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d4ede90fe8ac4b0c97634a13e76992c5",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ed1f72dcb7ea40b98de02ca4d8ff3450",
              "IPY_MODEL_7a2080455b4e4836a6559f2ac34a62be"
            ]
          }
        },
        "d4ede90fe8ac4b0c97634a13e76992c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ed1f72dcb7ea40b98de02ca4d8ff3450": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_5eb9c15b36004951a46ed666725ae3d5",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1896b6c605f641e2abcc15f47a32e6c5"
          }
        },
        "7a2080455b4e4836a6559f2ac34a62be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_17124afcca8b4b6aaffa1a8aef812748",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 623kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6292af23797c454fa5c35793b60ea12a"
          }
        },
        "5eb9c15b36004951a46ed666725ae3d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1896b6c605f641e2abcc15f47a32e6c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "17124afcca8b4b6aaffa1a8aef812748": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6292af23797c454fa5c35793b60ea12a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c0e29004e6e941f6b3d040ce9c59ff8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_7ad14b9929934e8c9fdb0893783b6956",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4b276327fb044207af38e6f074206ed7",
              "IPY_MODEL_a5a306829a41471b89181ed537a87893"
            ]
          }
        },
        "7ad14b9929934e8c9fdb0893783b6956": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4b276327fb044207af38e6f074206ed7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4103e3afebad465cb0d6882f10484e6d",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_37f3d97316cd46128e251ed0e18d211d"
          }
        },
        "a5a306829a41471b89181ed537a87893": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ad1ea58e1b5c493289f811d37b070078",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [01:32&lt;00:00, 4.69B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_dcd9f5c014404a778d5b1efe72c4fbe1"
          }
        },
        "4103e3afebad465cb0d6882f10484e6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "37f3d97316cd46128e251ed0e18d211d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ad1ea58e1b5c493289f811d37b070078": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "dcd9f5c014404a778d5b1efe72c4fbe1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e1466a1b00b74eada32c8e4e4072638e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a2357f299b424338b29636729647ea66",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ace739a5c2de40c1aa4a49a44f2375c0",
              "IPY_MODEL_66b7acce4037474ba61664bd6541365d"
            ]
          }
        },
        "a2357f299b424338b29636729647ea66": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ace739a5c2de40c1aa4a49a44f2375c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_04fac87b00c6447c972a8a1a69661a47",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9e579d31380a42f0b9767ac06c662462"
          }
        },
        "66b7acce4037474ba61664bd6541365d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_df91c99c16804b02b760011c0c16d76d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [00:05&lt;00:00, 77.3MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_56c9110b1e7144f29e2cdb258704097d"
          }
        },
        "04fac87b00c6447c972a8a1a69661a47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9e579d31380a42f0b9767ac06c662462": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "df91c99c16804b02b760011c0c16d76d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "56c9110b1e7144f29e2cdb258704097d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rykah14/DrugReviewDataset/blob/main/_DrugReviewDataset_multiclass_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLJShceY_jYM"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZPjC5oBSmko1",
        "outputId": "161d880d-54f6-4399-e21d-a341c6b1d7a5"
      },
      "source": [
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla P100-PCIE-16GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wmFO1My4mv9Q",
        "outputId": "71b0db9d-ca7d-449f-db18-f539a2bf1db1"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/50/0c/7d5950fcd80b029be0a8891727ba21e0cd27692c407c51261c3c921f6da3/transformers-4.1.1-py3-none-any.whl (1.5MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5MB 12.3MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 57.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.19.4)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.8)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Collecting tokenizers==0.9.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/1c/e789a8b12e28be5bc1ce2156cf87cb522b379be9cadc7ad8091a4cc107c4/tokenizers-0.9.4-cp36-cp36m-manylinux2010_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 59.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=e874972d150a854919be5b5175d8a6fe3e2f757cc3e97bade97b4c3d2ad88d4a\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.43 tokenizers-0.9.4 transformers-4.1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LlsBB2C9mzjC",
        "outputId": "d18b2f53-c69b-4a10-fcb9-4f2ff6a20227"
      },
      "source": [
        "!pip install wget"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wget\n",
            "  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-cp36-none-any.whl size=9682 sha256=ae5458b315c828ec027a64b6bc463dc36290686b595a47e64554738c0a9f9456\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mTOO2_xlm-f6",
        "outputId": "b987952e-b51a-4e94-a0d0-b6db171f25f2"
      },
      "source": [
        "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/00462/drugsCom_raw.zip"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-01-07 10:55:48--  https://archive.ics.uci.edu/ml/machine-learning-databases/00462/drugsCom_raw.zip\n",
            "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
            "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 42989872 (41M) [application/x-httpd-php]\n",
            "Saving to: ‘drugsCom_raw.zip’\n",
            "\n",
            "drugsCom_raw.zip    100%[===================>]  41.00M  13.5MB/s    in 3.0s    \n",
            "\n",
            "2021-01-07 10:55:51 (13.5 MB/s) - ‘drugsCom_raw.zip’ saved [42989872/42989872]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kBWUKrVNnAP5",
        "outputId": "87c37a9a-bd8f-431c-e008-38814758278c"
      },
      "source": [
        "!unzip drugsCom_raw.zip"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  drugsCom_raw.zip\n",
            "  inflating: drugsComTest_raw.tsv    \n",
            "  inflating: drugsComTrain_raw.tsv   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 563
        },
        "id": "HmriIuytnCpS",
        "outputId": "39846283-7b21-47ab-dca0-93e4aaf74639"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset into a pandas dataframe.\n",
        "df = pd.read_table(\"drugsComTest_raw.tsv\", delimiter='\\t', header=None, names=['drugName','condition','review',\t'rating'\t,'date','usefulCount'])\n",
        "\n",
        "# Report the number of sentences.\n",
        "print('Number of training sentences: {:,}\\n'.format(df.shape[0]))\n",
        "\n",
        "# Display 10 random rows from the data.\n",
        "df.sample(10)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training sentences: 53,767\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>drugName</th>\n",
              "      <th>condition</th>\n",
              "      <th>review</th>\n",
              "      <th>rating</th>\n",
              "      <th>date</th>\n",
              "      <th>usefulCount</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>82224.0</th>\n",
              "      <td>Liraglutide</td>\n",
              "      <td>Diabetes, Type 2</td>\n",
              "      <td>\"I have been using Victoza for nearly 2 years ...</td>\n",
              "      <td>9.0</td>\n",
              "      <td>March 13, 2016</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>210596.0</th>\n",
              "      <td>Mirtazapine</td>\n",
              "      <td>Depression</td>\n",
              "      <td>\"Worst psychiatric drug I&amp;#039;ve ever taken. ...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>August 26, 2017</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>122781.0</th>\n",
              "      <td>Linaclotide</td>\n",
              "      <td>Constipation, Chronic</td>\n",
              "      <td>\"I&amp;#039;ve been chronically constipated for as...</td>\n",
              "      <td>10.0</td>\n",
              "      <td>November 29, 2014</td>\n",
              "      <td>57</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36009.0</th>\n",
              "      <td>Buprenorphine / naloxone</td>\n",
              "      <td>Opiate Dependence</td>\n",
              "      <td>\"Well I have seen my husband going down and do...</td>\n",
              "      <td>9.0</td>\n",
              "      <td>February 6, 2011</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>215282.0</th>\n",
              "      <td>Lubiprostone</td>\n",
              "      <td>Constipation, Chronic</td>\n",
              "      <td>\"Have taken it for one day and I feel better a...</td>\n",
              "      <td>9.0</td>\n",
              "      <td>January 13, 2009</td>\n",
              "      <td>35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22205.0</th>\n",
              "      <td>Baclofen</td>\n",
              "      <td>Muscle Spasm</td>\n",
              "      <td>\"I was prescribed Baclofen to help spasms and ...</td>\n",
              "      <td>9.0</td>\n",
              "      <td>November 14, 2015</td>\n",
              "      <td>88</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>124679.0</th>\n",
              "      <td>Irbesartan</td>\n",
              "      <td>High Blood Pressure</td>\n",
              "      <td>\"I have been on Avapro about a week and do not...</td>\n",
              "      <td>7.0</td>\n",
              "      <td>June 10, 2010</td>\n",
              "      <td>72</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>183156.0</th>\n",
              "      <td>Cymbalta</td>\n",
              "      <td>Depression</td>\n",
              "      <td>\"I have been taking different medicines for de...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>October 21, 2013</td>\n",
              "      <td>24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>229709.0</th>\n",
              "      <td>Lurasidone</td>\n",
              "      <td>Schizophrenia</td>\n",
              "      <td>\"Excellent medicine in my experience.\\r\\n\\r\\nI...</td>\n",
              "      <td>10.0</td>\n",
              "      <td>January 12, 2013</td>\n",
              "      <td>79</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>171220.0</th>\n",
              "      <td>Levitra</td>\n",
              "      <td>Erectile Dysfunction</td>\n",
              "      <td>\"Have used Viagra 100MG split into halves or t...</td>\n",
              "      <td>9.0</td>\n",
              "      <td>February 3, 2014</td>\n",
              "      <td>114</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                          drugName  ... usefulCount\n",
              "82224.0                Liraglutide  ...          23\n",
              "210596.0               Mirtazapine  ...          11\n",
              "122781.0               Linaclotide  ...          57\n",
              "36009.0   Buprenorphine / naloxone  ...          10\n",
              "215282.0              Lubiprostone  ...          35\n",
              "22205.0                   Baclofen  ...          88\n",
              "124679.0                Irbesartan  ...          72\n",
              "183156.0                  Cymbalta  ...          24\n",
              "229709.0                Lurasidone  ...          79\n",
              "171220.0                   Levitra  ...         114\n",
              "\n",
              "[10 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zd-x2wkBrtJM"
      },
      "source": [
        "!sed -e 's/\"/'\\''/g' ./drugsComTest_raw.tsv > ./drugsComTest_raw_re.tsv"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BeYz7zs4mB5I",
        "outputId": "6d81321d-a144-4527-b049-19d0b929c58a"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# データの読込\n",
        "df = pd.read_table('./drugsComTest_raw_re.tsv', header=None, sep='\\t', names=['drugName','condition','review',\t'rating'\t,'date','usefulCount'])\n",
        "\n",
        "# データの抽出\n",
        "df = df.loc[df['condition'].isin(['Depression','Pain','Birth Control']), ['condition', 'review']]\n",
        "#multi class 分類をする\n",
        "#新たにBirth Controlを追加する\n",
        "df=df.replace('Depression', 0)\n",
        "df=df.replace('Pain', 1)\n",
        "df=df.replace('Birth Control', 2)\n",
        "#のちのことを考慮してint型の数値にreplace\n",
        "print(df[:10])\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "        condition                                             review\n",
            "163740          0  '''I&#039;ve tried a few antidepressants over ...\n",
            "97768           2  '''I have been on this birth control for one c...\n",
            "215892          2  '''I&#039;ve had the copper coil for about 3 m...\n",
            "71428           2  '''I was on this pill for almost two years. It...\n",
            "79865           2  '''I absolutely love this product and recommen...\n",
            "178004          1  '''Been on 30mg Cymbalta for 2 weeks. Started ...\n",
            "60341           2  '''I was on this for 5 years (and birth contro...\n",
            "141462          0  '''I am a 22 year old female college student. ...\n",
            "101371          2  '''I&#039;m absolutely DONE taking this horrib...\n",
            "17957           2  '''I started on the oral contraceptive pill bu...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "hqjLnuCQnbfL",
        "outputId": "3cf07855-554a-4ac4-cf3b-3b6a30daa3e0"
      },
      "source": [
        "df.loc[df.condition == 2].sample(5)[['condition','review']]"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>condition</th>\n",
              "      <th>review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>48374</th>\n",
              "      <td>2</td>\n",
              "      <td>'''I took this for one week. It gave me terrib...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16329</th>\n",
              "      <td>2</td>\n",
              "      <td>'''Other than mood swings and headaches, this ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18221</th>\n",
              "      <td>2</td>\n",
              "      <td>'''I have been using the Nuva-ring for about 5...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>81421</th>\n",
              "      <td>2</td>\n",
              "      <td>'''I&amp;#039;ve been on Yaz for just about a mont...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>165845</th>\n",
              "      <td>2</td>\n",
              "      <td>'''I was so terrified about the insertion but ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        condition                                             review\n",
              "48374           2  '''I took this for one week. It gave me terrib...\n",
              "16329           2  '''Other than mood swings and headaches, this ...\n",
              "18221           2  '''I have been using the Nuva-ring for about 5...\n",
              "81421           2  '''I&#039;ve been on Yaz for just about a mont...\n",
              "165845          2  '''I was so terrified about the insertion but ..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R4PBek_tnvi8"
      },
      "source": [
        "# Get the lists of sentences and their labels.\n",
        "conditions = df.condition.values\n",
        "reviews = df.review.values"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FeM-JgfvrcU6",
        "outputId": "492378fa-e380-4769-d20c-96933f6e6271"
      },
      "source": [
        "print(reviews[1:10])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[\"'''I have been on this birth control for one cycle. After reading some of the reviews on this type and similar birth controls I was a bit apprehensive to start. Im giving this birth control a 9 out of 10 as I have not been on it long enough for a 10. So far I love this birth control! My side effects have been so minimal its like Im not even on birth control! I have experienced mild headaches here and there and some nausea but other than that ive been feeling great! I got my period on cue on the third day of the inactive pills and I had no idea it was coming because I had zero pms! My period was very light and I barely had any cramping! I had unprotected sex the first month and obviously didn&#039;t get pregnant so I&#039;m very pleased! Highly recommend'''\"\n",
            " \"'''I&#039;ve had the copper coil for about 3 months now. I was really excited at the thought of not taking hormones. I&#039;m good with pain however I nearly fainted with insertion, couldn&#039;t belive how painful it was; the doctor did say it is very painful for some. Well 3 months in, my periods last 11 days and I&#039;m in pain for about 15 days with random twangs especially in the left side and I&#039;m considering whether I want to put up with the intense pain and heavy periods. I&#039;d recommend this 100% to somebody who doesn&#039;t already have heavy painful periods but right now it just isn&#039;t for me'''\"\n",
            " \"'''I was on this pill for almost two years. It does work as far as not getting pregnant however my experience at first was it didn&#039;t make a huge difference then 6 or 7 months into it my sex drive went down, along with being very very dry, my moodiness increased drastically. I would cry one second and then get angry with my husband over anything and everything. My skin has gotten a lot worse, I broke out in places I never had in the last week. So now I am on Yaz.'''\"\n",
            " \"'''I absolutely love this product and recommend to everyone. I know everyone&#039;s body is different, so it is not for everyone, but it is not the medicines fault. I have NO negative symptoms since I started this. I used to have heavy periods, terrible cramps and headaches, and my periods were super long. I now have super consistent 3-4 LIGHT periods, no cramps or headaches. I have been on this pill for over a year now and have no desire to switch.'''\"\n",
            " \"'''Been on 30mg Cymbalta for 2 weeks. Started getting relief by the 2nd day. Am 58 year old male with spinal stenosis, degenerative disc disease, and spondy. Plan was to go to 60mg but I am getting enough relief at 30mg. I believe I will try to stay on that dose to minimize side effects. Some constipation, difficult reaching orgasm, some night sweats and minor headaches. Oh, insomnia if I took it at night.  I had samples of this medicine for 6 months but delayed starting it because of horror stories on the internet. Pain was ruining my life so this medicine seems to be the best option.'''\"\n",
            " \"'''I was on this for 5 years (and birth control pills for about 12 years), and would have told you how fabulous it was.  &lt;List all the benefits everyone else has listed, here.&gt;  Then a friend of mine convinced me to stop birth control all together for a while, and I turned into a new and better person!  I dropped 5 lbs instantly, had a huge sex drive, more lubrication, and just felt better.  I wouldn&#039;t say I was depressed before, but after going off of it, I would describe my time on birth control as feeling like I was inside a cloud.  Less emotions in general, sometimes a little down.  I&#039;m bummed I&#039;m back on it, but it seems to be the least impactful than the others.  I might try Paragard to avoid the hormones.'''\"\n",
            " \"'''I am a 22 year old female college student. I wanted to write this because when I was at my lowest of low when I felt absolutely hopeless... these positive reviews are what got me through the day. I experienced a lot of change.  I was also in a relationship that made me unhappy. I stopped doing the things I liked to do such as run, party, work, hang out with friends etc. In result, I never had energy. I constantly felt guilty. I cried everyday, sometimes multiple times of day. I went to group therapy. I dropped 10lbs in two weeks. I eventually got on this medicine &amp; the first 4 days felt crazy &amp; tired! TAKE AT NIGHT. Give this medicine time! Now 3 weeks in I am back to myself and am truly happy! Keep your head up.'''\"\n",
            " \"'''I&#039;m absolutely DONE taking this horrible birth control! I&#039;ve  been taking Aubra for a month and a half... I&#039;m moody, irritable, depressed, hungry, bitchy... vaginal discharge has changed  (gross), my urine smells, my acne has gotten so out of hand and it&#039;s STUBBORN. Cystic acne all around my mouth, jawline, Chin and neck. After doing some research online, I discovered I&#039;m not the only one. Birth control is different for everyone but this is going in the trash... I will not be taking this any longer. It also kills your sex drive... as for the difference in bleeding, I wouldn&#039;t know. I started this pill on day 1 of menstrual cycle last month and haven&#039;t had a period yet... have had plenty of headaches though! '''\"\n",
            " \"'''I started on the oral contraceptive pill but got horrible nausea and vomiting, so this was my next option. NuvaRing has been fantastic, it has a fraction of the hormones and I get no nausea. Insertion and removing is really not a hassle, and you cannot feel it at all. For me, it beats the pill and vomiting, along with all the other symptoms. I haven&#039;t had any noticeable mood issues or migraines. I would recommend it to anyone!'''\"]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83,
          "referenced_widgets": [
            "f08fdc05320542b8864507310afa073f",
            "d4ede90fe8ac4b0c97634a13e76992c5",
            "ed1f72dcb7ea40b98de02ca4d8ff3450",
            "7a2080455b4e4836a6559f2ac34a62be",
            "5eb9c15b36004951a46ed666725ae3d5",
            "1896b6c605f641e2abcc15f47a32e6c5",
            "17124afcca8b4b6aaffa1a8aef812748",
            "6292af23797c454fa5c35793b60ea12a"
          ]
        },
        "id": "6Ynw9e--oOAk",
        "outputId": "8455ee45-ca4b-4e18-b3b1-78831713aa4c"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading BERT tokenizer...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f08fdc05320542b8864507310afa073f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mVWEoGPfoPpF",
        "outputId": "6785c1f7-78b8-4cf3-f650-657ddc43c50c"
      },
      "source": [
        "tokenizer"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PreTrainedTokenizer(name_or_path='bert-base-uncased', vocab_size=30522, model_max_len=512, is_fast=False, padding_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BfKYmw-zoUK6",
        "outputId": "47ebefb4-d7c1-4d69-be01-73c3525aa5f7"
      },
      "source": [
        "# Print the original sentence.\n",
        "print(' Original: ', reviews[10])\n",
        "\n",
        "# Print the sentence split into tokens.\n",
        "print('Tokenized: ', tokenizer.tokenize(reviews[10]))\n",
        "\n",
        "# Print the sentence mapped to token ids.\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(reviews[10])))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Original:  '''About two months ago I had to switch from LoLestrin Fe to microgestin due to my insurance and pharmacy. Since starting microgestin I&#039;ve noticed insane bloating and nausea and weird discharge. While on lolestrin, my periods consisted of spotting and average side effects, nothing too serious, but after one month of micro I got my period and it was heavy and the cramping was so painful I had to leave my class. I&#039;ve also noticed I&#039;ve developed bad depression and my mood swings are very intense. My anxiety is bad and my sex drive is very low if not nonexistent anymore. It helped with my acne but I&#039;m a lot more paranoid about getting pregnant than I was on lolestrin. I&#039;m going to be talking to my doctor about possibly getting the shot.'''\n",
            "Tokenized:  [\"'\", \"'\", \"'\", 'about', 'two', 'months', 'ago', 'i', 'had', 'to', 'switch', 'from', 'lo', '##les', '##tri', '##n', 'fe', 'to', 'micro', '##ges', '##tin', 'due', 'to', 'my', 'insurance', 'and', 'pharmacy', '.', 'since', 'starting', 'micro', '##ges', '##tin', 'i', '&', '#', '03', '##9', ';', 've', 'noticed', 'insane', 'b', '##lo', '##ating', 'and', 'nausea', 'and', 'weird', 'discharge', '.', 'while', 'on', 'lo', '##les', '##tri', '##n', ',', 'my', 'periods', 'consisted', 'of', 'spotting', 'and', 'average', 'side', 'effects', ',', 'nothing', 'too', 'serious', ',', 'but', 'after', 'one', 'month', 'of', 'micro', 'i', 'got', 'my', 'period', 'and', 'it', 'was', 'heavy', 'and', 'the', 'cr', '##amp', '##ing', 'was', 'so', 'painful', 'i', 'had', 'to', 'leave', 'my', 'class', '.', 'i', '&', '#', '03', '##9', ';', 've', 'also', 'noticed', 'i', '&', '#', '03', '##9', ';', 've', 'developed', 'bad', 'depression', 'and', 'my', 'mood', 'swings', 'are', 'very', 'intense', '.', 'my', 'anxiety', 'is', 'bad', 'and', 'my', 'sex', 'drive', 'is', 'very', 'low', 'if', 'not', 'none', '##xi', '##sten', '##t', 'anymore', '.', 'it', 'helped', 'with', 'my', 'ac', '##ne', 'but', 'i', '&', '#', '03', '##9', ';', 'm', 'a', 'lot', 'more', 'paranoid', 'about', 'getting', 'pregnant', 'than', 'i', 'was', 'on', 'lo', '##les', '##tri', '##n', '.', 'i', '&', '#', '03', '##9', ';', 'm', 'going', 'to', 'be', 'talking', 'to', 'my', 'doctor', 'about', 'possibly', 'getting', 'the', 'shot', '.', \"'\", \"'\", \"'\"]\n",
            "Token IDs:  [1005, 1005, 1005, 2055, 2048, 2706, 3283, 1045, 2018, 2000, 6942, 2013, 8840, 4244, 18886, 2078, 10768, 2000, 12702, 8449, 7629, 2349, 2000, 2026, 5427, 1998, 13882, 1012, 2144, 3225, 12702, 8449, 7629, 1045, 1004, 1001, 6021, 2683, 1025, 2310, 4384, 9577, 1038, 4135, 5844, 1998, 19029, 1998, 6881, 11889, 1012, 2096, 2006, 8840, 4244, 18886, 2078, 1010, 2026, 6993, 5031, 1997, 27963, 1998, 2779, 2217, 3896, 1010, 2498, 2205, 3809, 1010, 2021, 2044, 2028, 3204, 1997, 12702, 1045, 2288, 2026, 2558, 1998, 2009, 2001, 3082, 1998, 1996, 13675, 16613, 2075, 2001, 2061, 9145, 1045, 2018, 2000, 2681, 2026, 2465, 1012, 1045, 1004, 1001, 6021, 2683, 1025, 2310, 2036, 4384, 1045, 1004, 1001, 6021, 2683, 1025, 2310, 2764, 2919, 6245, 1998, 2026, 6888, 18755, 2024, 2200, 6387, 1012, 2026, 10089, 2003, 2919, 1998, 2026, 3348, 3298, 2003, 2200, 2659, 2065, 2025, 3904, 9048, 16173, 2102, 4902, 1012, 2009, 3271, 2007, 2026, 9353, 2638, 2021, 1045, 1004, 1001, 6021, 2683, 1025, 1049, 1037, 2843, 2062, 19810, 2055, 2893, 6875, 2084, 1045, 2001, 2006, 8840, 4244, 18886, 2078, 1012, 1045, 1004, 1001, 6021, 2683, 1025, 1049, 2183, 2000, 2022, 3331, 2000, 2026, 3460, 2055, 4298, 2893, 1996, 2915, 1012, 1005, 1005, 1005]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CvTb4M62pFr_",
        "outputId": "1ead8699-8234-42c2-89e7-aff25bfd80a3"
      },
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in reviews:\n",
        "    # `encode` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    encoded_sent = tokenizer.encode(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "\n",
        "                        # This function also supports truncation and conversion\n",
        "                        # to pytorch tensors, but we need to do padding, so we\n",
        "                        # can't use these features :( .\n",
        "                        #max_length = 128,          # Truncate all sentences.\n",
        "                        #return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.\n",
        "    input_ids.append(encoded_sent)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', reviews[10])\n",
        "print('Token IDs:', input_ids[10])"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (609 > 512). Running this sequence through the model will result in indexing errors\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Original:  '''About two months ago I had to switch from LoLestrin Fe to microgestin due to my insurance and pharmacy. Since starting microgestin I&#039;ve noticed insane bloating and nausea and weird discharge. While on lolestrin, my periods consisted of spotting and average side effects, nothing too serious, but after one month of micro I got my period and it was heavy and the cramping was so painful I had to leave my class. I&#039;ve also noticed I&#039;ve developed bad depression and my mood swings are very intense. My anxiety is bad and my sex drive is very low if not nonexistent anymore. It helped with my acne but I&#039;m a lot more paranoid about getting pregnant than I was on lolestrin. I&#039;m going to be talking to my doctor about possibly getting the shot.'''\n",
            "Token IDs: [101, 1005, 1005, 1005, 2055, 2048, 2706, 3283, 1045, 2018, 2000, 6942, 2013, 8840, 4244, 18886, 2078, 10768, 2000, 12702, 8449, 7629, 2349, 2000, 2026, 5427, 1998, 13882, 1012, 2144, 3225, 12702, 8449, 7629, 1045, 1004, 1001, 6021, 2683, 1025, 2310, 4384, 9577, 1038, 4135, 5844, 1998, 19029, 1998, 6881, 11889, 1012, 2096, 2006, 8840, 4244, 18886, 2078, 1010, 2026, 6993, 5031, 1997, 27963, 1998, 2779, 2217, 3896, 1010, 2498, 2205, 3809, 1010, 2021, 2044, 2028, 3204, 1997, 12702, 1045, 2288, 2026, 2558, 1998, 2009, 2001, 3082, 1998, 1996, 13675, 16613, 2075, 2001, 2061, 9145, 1045, 2018, 2000, 2681, 2026, 2465, 1012, 1045, 1004, 1001, 6021, 2683, 1025, 2310, 2036, 4384, 1045, 1004, 1001, 6021, 2683, 1025, 2310, 2764, 2919, 6245, 1998, 2026, 6888, 18755, 2024, 2200, 6387, 1012, 2026, 10089, 2003, 2919, 1998, 2026, 3348, 3298, 2003, 2200, 2659, 2065, 2025, 3904, 9048, 16173, 2102, 4902, 1012, 2009, 3271, 2007, 2026, 9353, 2638, 2021, 1045, 1004, 1001, 6021, 2683, 1025, 1049, 1037, 2843, 2062, 19810, 2055, 2893, 6875, 2084, 1045, 2001, 2006, 8840, 4244, 18886, 2078, 1012, 1045, 1004, 1001, 6021, 2683, 1025, 1049, 2183, 2000, 2022, 3331, 2000, 2026, 3460, 2055, 4298, 2893, 1996, 2915, 1012, 1005, 1005, 1005, 102]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iQ95z3iJodpM",
        "outputId": "a89e37ae-1c31-4d90-ec01-12a833686359"
      },
      "source": [
        "print('Max sentence length: ', max([len(sen) for sen in input_ids]))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max sentence length:  609\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cdsuPu0-vvfk",
        "outputId": "345caa59-eab8-48b7-a37b-78c87f9d6dec"
      },
      "source": [
        "# We'll borrow the `pad_sequences` utility function to do this.\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Set the maximum sequence length.\n",
        "# I've chosen 64 somewhat arbitrarily. It's slightly larger than the\n",
        "# maximum training sentence length of 47...\n",
        "MAX_LEN = 64\n",
        "\n",
        "print('\\nPadding/truncating all sentences to %d values...' % MAX_LEN)\n",
        "\n",
        "print('\\nPadding token: \"{:}\", ID: {:}'.format(tokenizer.pad_token, tokenizer.pad_token_id))\n",
        "\n",
        "# Pad our input tokens with value 0.\n",
        "# \"post\" indicates that we want to pad and truncate at the end of the sequence,\n",
        "# as opposed to the beginning.\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", \n",
        "                          value=0, truncating=\"post\", padding=\"post\")\n",
        "\n",
        "print('\\nDone.')"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Padding/truncating all sentences to 64 values...\n",
            "\n",
            "Padding token: \"[PAD]\", ID: 0\n",
            "\n",
            "Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzpunIbLv01M"
      },
      "source": [
        "# Create attention masks\n",
        "attention_masks = []\n",
        "\n",
        "# For each sentence...\n",
        "for sent in input_ids:\n",
        "    \n",
        "    # Create the attention mask.\n",
        "    #   - If a token ID is 0, then it's padding, set the mask to 0.\n",
        "    #   - If a token ID is > 0, then it's a real token, set the mask to 1.\n",
        "    att_mask = [int(token_id > 0) for token_id in sent]\n",
        "    \n",
        "    # Store the attention mask for this sentence.\n",
        "    attention_masks.append(att_mask)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38A6GW3kv5cf"
      },
      "source": [
        "# Use train_test_split to split our data into train and validation sets for\n",
        "# training\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Use 90% for training and 10% for validation.\n",
        "train_inputs, validation_inputs, train_conditions, validation_conditions = train_test_split(input_ids, conditions, \n",
        "                                                            random_state=2018, test_size=0.1)\n",
        "# Do the same for the masks.\n",
        "train_masks, validation_masks, _, _ = train_test_split(attention_masks, conditions,\n",
        "                                             random_state=2018, test_size=0.1)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLdBvHg8wJQn"
      },
      "source": [
        "# Convert all inputs and labels into torch tensors, the required datatype \n",
        "# for our model.\n",
        "train_inputs = torch.tensor(train_inputs)\n",
        "validation_inputs = torch.tensor(validation_inputs)\n",
        "\n",
        "train_conditions = torch.tensor(train_conditions)\n",
        "validation_conditions = torch.tensor(validation_conditions)\n",
        "\n",
        "train_masks = torch.tensor(train_masks)\n",
        "validation_masks = torch.tensor(validation_masks)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ag0pjb1C4J-f"
      },
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# The DataLoader needs to know our batch size for training, so we specify it \n",
        "# here.\n",
        "# For fine-tuning BERT on a specific task, the authors recommend a batch size of\n",
        "# 16 or 32.\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "# Create the DataLoader for our training set.\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_conditions)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "# Create the DataLoader for our validation set.\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_conditions)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "c0e29004e6e941f6b3d040ce9c59ff8f",
            "7ad14b9929934e8c9fdb0893783b6956",
            "4b276327fb044207af38e6f074206ed7",
            "a5a306829a41471b89181ed537a87893",
            "4103e3afebad465cb0d6882f10484e6d",
            "37f3d97316cd46128e251ed0e18d211d",
            "ad1ea58e1b5c493289f811d37b070078",
            "dcd9f5c014404a778d5b1efe72c4fbe1",
            "e1466a1b00b74eada32c8e4e4072638e",
            "a2357f299b424338b29636729647ea66",
            "ace739a5c2de40c1aa4a49a44f2375c0",
            "66b7acce4037474ba61664bd6541365d",
            "04fac87b00c6447c972a8a1a69661a47",
            "9e579d31380a42f0b9767ac06c662462",
            "df91c99c16804b02b760011c0c16d76d",
            "56c9110b1e7144f29e2cdb258704097d"
          ]
        },
        "id": "7GVNU1HErqst",
        "outputId": "9789c863-48ac-4fcc-d568-ea64615faf50"
      },
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
        "# linear classification layer on top. \n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
        "    num_labels = 3, # The number of output labels--2 for binary classification.\n",
        "                    # You can increase this for multi-class tasks.   \n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        ")\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model.cuda()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c0e29004e6e941f6b3d040ce9c59ff8f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e1466a1b00b74eada32c8e4e4072638e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GXobR03zsHyh",
        "outputId": "8ed55c38-7671-4bc3-fceb-e99f42eae6f3"
      },
      "source": [
        "# Get all of the model's parameters as a list of tuples.\n",
        "params = list(model.named_parameters())\n",
        "\n",
        "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
        "\n",
        "print('==== Embedding Layer ====\\n')\n",
        "\n",
        "for p in params[0:5]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== First Transformer ====\\n')\n",
        "\n",
        "for p in params[5:21]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== Output Layer ====\\n')\n",
        "\n",
        "for p in params[-4:]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The BERT model has 201 different named parameters.\n",
            "\n",
            "==== Embedding Layer ====\n",
            "\n",
            "bert.embeddings.word_embeddings.weight                  (30522, 768)\n",
            "bert.embeddings.position_embeddings.weight                (512, 768)\n",
            "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
            "bert.embeddings.LayerNorm.weight                              (768,)\n",
            "bert.embeddings.LayerNorm.bias                                (768,)\n",
            "\n",
            "==== First Transformer ====\n",
            "\n",
            "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
            "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
            "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
            "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
            "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
            "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
            "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
            "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
            "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
            "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
            "\n",
            "==== Output Layer ====\n",
            "\n",
            "bert.pooler.dense.weight                                  (768, 768)\n",
            "bert.pooler.dense.bias                                        (768,)\n",
            "classifier.weight                                           (3, 768)\n",
            "classifier.bias                                                 (3,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQmmZgnesJb0"
      },
      "source": [
        "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
        "# I believe the 'W' stands for 'Weight Decay fix\"\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "             \n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJLAsdgZsL_Y",
        "outputId": "7b8a1efd-a3bd-4e9d-f823-ae5edd104c9c"
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs (authors recommend between 2 and 4)\n",
        "epochs = 4\n",
        "\n",
        "# Total number of training steps is number of batches * number of epochs.\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)\n",
        "scheduler"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.optim.lr_scheduler.LambdaLR at 0x7fc22e4af438>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AMgLdT0LsO8t"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3FJbbti9sSNW"
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79Z5pm6NsUed",
        "outputId": "70aeda0d-3f65-41ed-d988-54a1bd8f6567"
      },
      "source": [
        "import random\n",
        "\n",
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# Store the average loss after each epoch so we can plot them.\n",
        "loss_values = []\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_loss = 0\n",
        "\n",
        "    # Put the model into training mode. Don't be mislead--the call to \n",
        "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "    # `dropout` and `batchnorm` layers behave differently during training\n",
        "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "        # `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a\n",
        "        # backward pass. PyTorch doesn't do this automatically because \n",
        "        # accumulating the gradients is \"convenient while training RNNs\". \n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "        model.zero_grad()        \n",
        "\n",
        "        # Perform a forward pass (evaluate the model on this training batch).\n",
        "        # This will return the loss (rather than the model output) because we\n",
        "        # have provided the `labels`.\n",
        "        # The documentation for this `model` function is here: \n",
        "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "        outputs = model(b_input_ids, \n",
        "                    token_type_ids=None, \n",
        "                    attention_mask=b_input_mask, \n",
        "                    labels=b_labels)\n",
        "        \n",
        "        # The call to `model` always returns a tuple, so we need to pull the \n",
        "        # loss value out of the tuple.\n",
        "        loss = outputs[0]\n",
        "\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value \n",
        "        # from the tensor.\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over the training data.\n",
        "    avg_train_loss = total_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Store the loss value for plotting the learning curve.\n",
        "    loss_values.append(avg_train_loss)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        # Add batch to GPU\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        \n",
        "        # Unpack the inputs from our dataloader\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        \n",
        "        # Telling the model not to compute or store gradients, saving memory and\n",
        "        # speeding up validation\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # This will return the logits rather than the loss because we have\n",
        "            # not provided labels.\n",
        "            # token_type_ids is the same as the \"segment ids\", which \n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "            # The documentation for this `model` function is here: \n",
        "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "            outputs = model(b_input_ids, \n",
        "                            token_type_ids=None, \n",
        "                            attention_mask=b_input_mask)\n",
        "        \n",
        "        # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "        # values prior to applying an activation function like the softmax.\n",
        "        logits = outputs[0]\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "        \n",
        "        # Calculate the accuracy for this batch of test sentences.\n",
        "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "        \n",
        "        # Accumulate the total accuracy.\n",
        "        eval_accuracy += tmp_eval_accuracy\n",
        "\n",
        "        # Track the number of batches\n",
        "        nb_eval_steps += 1\n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
        "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    418.    Elapsed: 0:00:09.\n",
            "  Batch    80  of    418.    Elapsed: 0:00:17.\n",
            "  Batch   120  of    418.    Elapsed: 0:00:26.\n",
            "  Batch   160  of    418.    Elapsed: 0:00:35.\n",
            "  Batch   200  of    418.    Elapsed: 0:00:43.\n",
            "  Batch   240  of    418.    Elapsed: 0:00:52.\n",
            "  Batch   280  of    418.    Elapsed: 0:01:00.\n",
            "  Batch   320  of    418.    Elapsed: 0:01:09.\n",
            "  Batch   360  of    418.    Elapsed: 0:01:17.\n",
            "  Batch   400  of    418.    Elapsed: 0:01:26.\n",
            "\n",
            "  Average training loss: 0.24\n",
            "  Training epcoh took: 0:01:30\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.97\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    418.    Elapsed: 0:00:09.\n",
            "  Batch    80  of    418.    Elapsed: 0:00:17.\n",
            "  Batch   120  of    418.    Elapsed: 0:00:26.\n",
            "  Batch   160  of    418.    Elapsed: 0:00:34.\n",
            "  Batch   200  of    418.    Elapsed: 0:00:43.\n",
            "  Batch   240  of    418.    Elapsed: 0:00:51.\n",
            "  Batch   280  of    418.    Elapsed: 0:01:00.\n",
            "  Batch   320  of    418.    Elapsed: 0:01:08.\n",
            "  Batch   360  of    418.    Elapsed: 0:01:17.\n",
            "  Batch   400  of    418.    Elapsed: 0:01:25.\n",
            "\n",
            "  Average training loss: 0.07\n",
            "  Training epcoh took: 0:01:29\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.98\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    418.    Elapsed: 0:00:09.\n",
            "  Batch    80  of    418.    Elapsed: 0:00:17.\n",
            "  Batch   120  of    418.    Elapsed: 0:00:26.\n",
            "  Batch   160  of    418.    Elapsed: 0:00:34.\n",
            "  Batch   200  of    418.    Elapsed: 0:00:43.\n",
            "  Batch   240  of    418.    Elapsed: 0:00:51.\n",
            "  Batch   280  of    418.    Elapsed: 0:01:00.\n",
            "  Batch   320  of    418.    Elapsed: 0:01:08.\n",
            "  Batch   360  of    418.    Elapsed: 0:01:17.\n",
            "  Batch   400  of    418.    Elapsed: 0:01:25.\n",
            "\n",
            "  Average training loss: 0.03\n",
            "  Training epcoh took: 0:01:29\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.98\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    418.    Elapsed: 0:00:08.\n",
            "  Batch    80  of    418.    Elapsed: 0:00:17.\n",
            "  Batch   120  of    418.    Elapsed: 0:00:25.\n",
            "  Batch   160  of    418.    Elapsed: 0:00:34.\n",
            "  Batch   200  of    418.    Elapsed: 0:00:42.\n",
            "  Batch   240  of    418.    Elapsed: 0:00:51.\n",
            "  Batch   280  of    418.    Elapsed: 0:00:59.\n",
            "  Batch   320  of    418.    Elapsed: 0:01:08.\n",
            "  Batch   360  of    418.    Elapsed: 0:01:16.\n",
            "  Batch   400  of    418.    Elapsed: 0:01:25.\n",
            "\n",
            "  Average training loss: 0.02\n",
            "  Training epcoh took: 0:01:29\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.98\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "Training complete!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "id": "DFK47fx6tjxm",
        "outputId": "f3b6ba05-7ad2-4550-dae4-e3979f24c3ad"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(loss_values, 'b-o')\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.show()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}